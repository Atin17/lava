{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright (C) 2021 Intel Corporation*<br>\n",
    "*SPDX-License-Identifier: BSD-3-Clause*<br>\n",
    "*See: https://spdx.org/licenses/*\n",
    "\n",
    "---\n",
    "\n",
    "# Three Factor Learning with Lava \n",
    "\n",
    "_**Motivation**: In this tutorial, we will demonstrate the simple mechanics of a three factor learning rule using a software model of Loihi's learning engine, exposed in Lava. This involves the definition of a reward-modulated synaptic plasticity rule with eligibility traces and reward signals_\n",
    "\n",
    "#### This tutorial assumes that you:\n",
    "- have the [Lava framework installed](../../in_depth/tutorial01_installing_lava.ipynb \"Tutorial on Installing Lava\")\n",
    "- are familiar with the [Process concept in Lava](../../in_depth/tutorial02_processes.ipynb \"Tutorial on Processes\")\n",
    "- are familiar with the [ProcessModel concept in Lava](../../in_depth/tutorial02_process_models.ipynb \"Tutorial on ProcessModels\")\n",
    "- are familiar with how to [connect Lava Processes](../../in_depth/tutorial05_connect_processes.ipynb \"Tutorial on connecting Processes\")\n",
    "- are familiar with how to [Implement a custom learning rule](../../in_depth/tutorial08_stdp.ipynb \"Tutorial on STDP\")\n",
    "\n",
    "This tutorial gives a bird's-eye view of how to create a three-factor learning rule using the Lava process libraries. For this purpose, we will create a network of LIF and Dense processes with one plastic connection and generate frozen patterns of activity. We can easily choose between a floating point simulation of the learning engine and a fixed point simulation, which approximates the behavior on the Loihi neuromorphic hardware. We also will create monitors to observe the behavior of the weights and activity traces of the neurons and learning rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Modulated Spike-timing Dependent Plasticity (R-STDP) Learning rule\n",
    "\n",
    "Reward-modulated STDP is a learning rule that can explain how behaviourly relevant adaptive changes in complex network of spiking neurons could be achieved in a self-organizing manner through local synaptic plasticity. The main idea is to modulate the outcome of a pairwise two-factor learning rule like STDP by a reward term. The implementation of the R-STDP described below is adapted from [Neuro-modulated Spike-Timing-Dependent Plasticity](https://www.frontiersin.org/articles/10.3389/fncir.2015.00085/full \"Neuromodulated Spike-Timing-Dependent Plasticity, and Theory of Three-Factor Learning Rules\"). \n",
    "\n",
    "The magnitude of weight change is implemented as a function of the synaptic eligibility trace $e$ and a reward term $R$. A synaptic eligibility trace, is used to store a temporary memory of the STDP outcome so that it is still available by the time a delayed reward signal is received. If you define the learning window of a traditional hebbian STDP as $STDP(pre, post)$, where \"pre\" represents the pre-synaptic activity of a synapse and \"post\" represents the state of the post-synaptic neuron, the synaptic eligibility trace dynamics can be represented in the form:\n",
    "\n",
    "$$\\dot{E} = - \\frac{E}{\\tau_e} + STDP(pre, post)$$\n",
    "\n",
    "where $\\tau_e$ is the time constant of the eligibility trace. In R-STDP, the synaptic weight, $W$, is modulated based on:\n",
    "\n",
    "$$\\dot{W} = R \\cdot E."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiating an R-STDP learning rule with learning-related parameters. \n",
    "\n",
    "We define the eligibility trace $\\dot{E}$ in the sum-of-products form using the tag variable $t$ and describe its dynamics $dt$ as:\n",
    "\n",
    "$$dt = ( A_{+} \\cdot x_0 \\cdot y_1 + A_{-} \\cdot y_0 \\cdot x_1 ) - t \\cdot tag\\_tau$$\n",
    "\n",
    "Here, $dt$ represents a simple pairwise-STDP learning rule with $A_{+} < 0$ and $A_{-} > 0$. The Reward-modulated STDP is defined by the synaptic weight change variable $dw$ in the form:\n",
    "\n",
    "$$dw = u_0 \\cdot t \\cdot y_2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIALIZING LEARNING-RELATED PARAMETERS\n",
    "from lava.magma.core.learning.learning_rule import LoihiLearningRule\n",
    "\n",
    "# Learning rule coefficient\n",
    "A_plus = -2\n",
    "A_minus = 2\n",
    "\n",
    "learning_rate = 1\n",
    "\n",
    "# Trace decay constants\n",
    "x1_tau = 10\n",
    "y1_tau = 10\n",
    "\n",
    "# Eligibility trace decay constant\n",
    "tag_tau = 10 # Verify\n",
    "\n",
    "# High Reward decay constant for negligible decay\n",
    "y2_tau = 2 ** 32-1\n",
    "\n",
    "# Impulses\n",
    "x1_impulse = 16\n",
    "y1_impulse = 16\n",
    "\n",
    "# Zero impulse value for reward. \n",
    "y2_impulse = 0\n",
    "\n",
    "# Epoch length\n",
    "t_epoch = 2\n",
    "\n",
    "#string learning rule for dt : ELIGIBILITY TRACE represented as tag_1\n",
    "dt = f\"{learning_rate} * {A_plus} * x0 * y1 +\" \\\n",
    "     f\"{learning_rate} * {A_minus} * y0 * x1 - t * {tag_tau}\"\n",
    "\n",
    "# String learning rule for dw\n",
    "# The weights are updated at every-timestep and the magnitude is a product of y2 (R) and de (tag_1)\n",
    "dw = \" u0 * t * y2 \"\n",
    "\n",
    "\n",
    "# Create custom LearningRule\n",
    "R_STDP = LoihiLearningRule(dw=dw,\n",
    "                         x1_impulse=x1_impulse,\n",
    "                         x1_tau=x1_tau,\n",
    "                         y1_impulse=y1_impulse,\n",
    "                         y1_tau=y1_tau,\n",
    "                         y2_impulse=y2_impulse,\n",
    "                         y2_tau=y2_tau,\n",
    "                         t_epoch=t_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Parameters and Spike Inputs\n",
    "\n",
    "We now define the parameters of the network and generate frozen and random input spikes that act as inputs to the pre and post-synaptic inputs. We also generate graded reward spikes that are used to set the third-factor in the post-synaptic neuron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set this tag to \"fixed_pt\" or \"floating_pt\" to choose the corresponding models.\n",
    "SELECT_TAG = \"floating_pt\"\n",
    "\n",
    "# LIF parameters : Only supports floating_pt for now. \n",
    "if SELECT_TAG == \"floating_pt\":\n",
    "    du = 1\n",
    "    dv = 1\n",
    "\n",
    "vth = 240\n",
    "\n",
    "# Number of pre-synaptic neurons per layer\n",
    "num_neurons_pre = 1\n",
    "shape_lif_pre = (num_neurons_pre, )\n",
    "shape_conn_pre = (num_neurons_pre, num_neurons_pre)\n",
    "\n",
    "# Number of post-synaptic neurons per layer\n",
    "num_neurons_post = 2\n",
    "shape_lif_post = (num_neurons_post, )\n",
    "shape_conn_post = (num_neurons_post, num_neurons_post)\n",
    "\n",
    "# Connection parameters\n",
    "\n",
    "# SpikePattern -> LIF connection weight : PRE-synaptic\n",
    "wgt_inp_pre = np.eye(num_neurons_pre) * 250\n",
    "\n",
    "# SpikePattern -> LIF connection weight : POST-synaptic\n",
    "wgt_inp_post = np.eye(num_neurons_post) * 250\n",
    "\n",
    "# LIF -> LIF connection initial weight (learning-enabled)\n",
    "wgt_plast_conn = np.full(shape_conn_post, 50)\n",
    "    \n",
    "# Number of simulation time steps\n",
    "num_steps = 200\n",
    "time = list(range(1, num_steps + 1))\n",
    "\n",
    "# Spike times\n",
    "spike_prob = 0.03\n",
    "\n",
    "# Create spike rasters\n",
    "np.random.seed(123)\n",
    "spike_raster_pre = np.zeros((num_neurons, num_steps))\n",
    "np.place(spike_raster_pre, np.random.rand(num_neurons, num_steps) < spike_prob, 1)\n",
    "\n",
    "spike_raster_post = np.zeros((num_neurons, num_steps))\n",
    "np.place(spike_raster_post, np.random.rand(num_neurons, num_steps) < spike_prob, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Network\n",
    "The following diagram depics the Lava Process architecture used in this tutorial. It consists of:\n",
    "- 2 Constant pattern generators for injecting spike trains to Leaky-Intergrate and Fire (LIF) neurons.\n",
    "- 2 _LIF_ Processes representing pre- and post-synaptic Leaky Integrate-and-Fire neurons.\n",
    "- 1 _LearningDense_ Process representing learning-enabled connection between LIF neurons.\n",
    "\n",
    ">**Note:** \n",
    "All neuronal population (spike generator, LIF) are composed of only 1 neuron in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![R_STDP_architecture](r_stdp_tutorial_architecture_2.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.proc.lif.process import LIF\n",
    "from lava.proc.lif.process import LearningLIF\n",
    "from lava.proc.io.source import RingBuffer\n",
    "from lava.proc.dense.process import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input devices\n",
    "pattern_pre = RingBuffer(data=spike_raster_pre.astype(int))\n",
    "pattern_post = RingBuffer(data=spike_raster_post.astype(int))\n",
    "\n",
    "# Create input connectivity\n",
    "conn_inp_pre = Dense(weights=wgt_inp)\n",
    "conn_inp_post = Dense(weights=wgt_inp)\n",
    "\n",
    "# Create pre-synaptic neurons\n",
    "lif_pre = LIF(u=0,\n",
    "              v=0,\n",
    "              du=du,\n",
    "              dv=du,\n",
    "              bias_mant=0,\n",
    "              bias_exp=0,\n",
    "              vth=vth,\n",
    "              shape=shape_lif,\n",
    "              name='lif_pre')\n",
    "\n",
    "# Create plastic connection\n",
    "plast_conn = Dense(weights=wgt_plast_conn,\n",
    "                   learning_rule=R_STDP,\n",
    "                   name='plastic_dense')\n",
    "\n",
    "# Create post-synaptic neuron\n",
    "lif_post = LearningLIF(u=0,\n",
    "               v=0,\n",
    "               du=du,\n",
    "               dv=du,\n",
    "               bias_mant=0,\n",
    "               bias_exp=0,\n",
    "               vth=vth,\n",
    "               shape=shape_lif,\n",
    "               name='lif_post')\n",
    "\n",
    "# Connect network\n",
    "pattern_pre.s_out.connect(conn_inp_pre.s_in)\n",
    "conn_inp_pre.a_out.connect(lif_pre.a_in)\n",
    "\n",
    "pattern_post.s_out.connect(conn_inp_post.s_in)\n",
    "conn_inp_post.a_out.connect(lif_post.a_in)\n",
    "\n",
    "lif_pre.s_out.connect(plast_conn.s_in)\n",
    "plast_conn.a_out.connect(lif_post.a_in)\n",
    "\n",
    "# VERIFY\n",
    "# Connect back-propagating actionpotential (BAP)\n",
    "lif_post.s_out_bap.connect(plast_conn.s_in_bap)\n",
    "\n",
    "# Connect reward trace callback (y2)\n",
    "lif_post.s_out_y2.connect(plast_conn.s_in_y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create monitors to observe traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.proc.monitor.process import Monitor\n",
    "\n",
    "# Create monitors\n",
    "mon_pre_trace = Monitor()\n",
    "mon_post_trace = Monitor()\n",
    "mon_reward_trace = Monitor()\n",
    "mon_pre_spikes = Monitor()\n",
    "mon_post_spikes = Monitor()\n",
    "mon_weight = Monitor()\n",
    "\n",
    "# Connect monitors\n",
    "mon_pre_trace.probe(plast_conn.x1, num_steps)\n",
    "mon_post_trace.probe(plast_conn.y1, num_steps)\n",
    "mon_reward_trace.probe(plast_conn.y2, num_steps)\n",
    "mon_pre_spikes.probe(lif_pre.s_out, num_steps)\n",
    "mon_post_spikes.probe(lif_post.s_out, num_steps)\n",
    "mon_weight.probe(plast_conn.weights, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi1SimCfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running\n",
    "pattern_pre.run(condition=RunSteps(num_steps=num_steps), run_cfg=Loihi1SimCfg(select_tag=SELECT_TAG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from monitors\n",
    "pre_trace = mon_pre_trace.get_data()['plastic_dense']['x1']\n",
    "post_trace = mon_post_trace.get_data()['plastic_dense']['y1']\n",
    "reward_trace = mon_reward_trace.get_data()['plastic_dense']['y2']\n",
    "pre_spikes = mon_pre_spikes.get_data()['lif_pre']['s_out']\n",
    "post_spikes = mon_post_spikes.get_data()['lif_post']['s_out']\n",
    "weights = mon_weight.get_data()['plastic_dense']['weights'][:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopping\n",
    "pattern_pre.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pyvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9675ffdc91e60dd2f22941f77cf588df3145db12507b97bfc4da6c5719f82313"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
